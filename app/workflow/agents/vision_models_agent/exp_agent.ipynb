{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc712980",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\cuda\\__init__.py:61: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(r\"C:\\My Projects\\Health-Navigator\")\n",
    "\n",
    "\n",
    "from langchain.agents import create_agent\n",
    "from langchain.tools import tool\n",
    "from langchain_community.agent_toolkits.sql.toolkit import SQLDatabaseToolkit\n",
    "from langchain_community.utilities.sql_database import SQLDatabase\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from dotenv import load_dotenv\n",
    "import time\n",
    "import os\n",
    "load_dotenv(r'C:\\My Projects\\Health-Navigator\\credentials.env')\n",
    "\n",
    "from app.workflow.ml_models.vision_models.colon_tissue_classifier.colon import classify_colon\n",
    "from app.workflow.ml_models.vision_models.chest_xray.chest_xray import classify_chest_xray\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4571416c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def classify_colon_tissue_tool(image_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Classifies colon tissue histopathology images into 9 tissue types.\n",
    "    \n",
    "    Args:\n",
    "        image_path (str): Absolute path to the colon tissue image file.\n",
    "    \n",
    "    Returns:\n",
    "        str: Predicted tissue type - one of: Adipose, Background, Debris, Lymphocytes, \n",
    "             Mucus, Smooth Muscle, Normal Colon Mucosa, Cancer-associated Stroma, \n",
    "             or Colorectal Adenocarcinoma Epithelium\n",
    "    \n",
    "    Example:\n",
    "        classify_colon_tissue_tool(\"C:/images/sample.jpg\")\n",
    "        Returns: \"Colorectal Adenocarcinoma Epithelium\"\n",
    "    \"\"\"\n",
    "    try:\n",
    "        result = classify_colon(image_path)\n",
    "        return result\n",
    "    except FileNotFoundError:\n",
    "        return f\"Error: Image not found at {image_path}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def classify_chest_xray_tool(image_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Classifies chest X-ray images for 14 thoracic pathologies (multi-label classification).\n",
    "    \n",
    "    Args:\n",
    "        image_path (str): Absolute path to the chest X-ray image (grayscale).\n",
    "    \n",
    "    Returns:\n",
    "        str: String listing detected pathologies with confidence scores, or \n",
    "             \"No significant findings\" if none detected above 0.5 threshold.\n",
    "             \n",
    "             Detectable conditions: Atelectasis, Cardiomegaly, Effusion, Infiltration, \n",
    "             Mass, Nodule, Pneumonia, Pneumothorax, Consolidation, Edema, Emphysema, \n",
    "             Fibrosis, Pleural_Thickening, Hernia\n",
    "    \n",
    "    Example:\n",
    "        classify_chest_xray_tool(\"C:/images/xray.jpg\")\n",
    "        Returns: \"Pneumonia (0.78), Infiltration (0.62)\"\n",
    "    \"\"\"\n",
    "    try:\n",
    "        results = classify_chest_xray(image_path)\n",
    "        if not results:\n",
    "            return \"No significant findings detected\"\n",
    "        return results\n",
    "    except FileNotFoundError:\n",
    "        return f\"Error: Image not found at {image_path}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "    \n",
    "agent = None\n",
    "\n",
    "def initialize_agent():\n",
    "    global agent\n",
    "    # Setup agent\n",
    "    tools = [classify_colon_tissue_tool, classify_chest_xray_tool]\n",
    "\n",
    "    system_prompt = \"\"\"You are a Medical Image Classification Agent specialized in analyzing medical images using deep learning models. You are a component within a larger healthcare AI system and your role is strictly limited to image classification and result reporting.\n",
    "\n",
    "## YOUR CORE RESPONSIBILITY\n",
    "Process medical images by routing them to appropriate machine learning models and returning predictions. You do NOT provide medical advice, diagnoses, treatment recommendations, or clinical interpretations beyond the raw model outputs.\n",
    "\n",
    "## AVAILABLE CLASSIFICATION MODELS\n",
    "\n",
    "### 1. Colon Tissue Histopathology Classifier (classify_colon_tissue_tool)\n",
    "- **Purpose**: Classifies colon tissue biopsy images into 9 distinct tissue types\n",
    "- **Input**: Absolute file path to histopathology image (JPG, PNG formats)\n",
    "- **Output**: Single class label from:\n",
    "  * \"Adipose\" - Fat tissue\n",
    "  * \"Background\" - Non-tissue background\n",
    "  * \"Debris\" - Cellular debris/artifacts\n",
    "  * \"Lymphocytes\" - Immune system cells\n",
    "  * \"Mucus\" - Mucus-producing tissue\n",
    "  * \"Smooth Muscle\" - Smooth muscle tissue\n",
    "  * \"Normal Colon Mucosa\" - Healthy colon lining\n",
    "  * \"Cancer-associated Stroma\" - Supportive tissue surrounding cancer\n",
    "  * \"Colorectal Adenocarcinoma Epithelium\" - Cancerous colon epithelial cells\n",
    "- **Model Architecture**: ResNet18-based classifier trained on histopathology data\n",
    "- **Use When**: Image classification type is \"colon\", \"colon_tissue\", or similar variants\n",
    "\n",
    "### 2. Chest X-Ray Multi-Label Classifier (classify_chest_xray_tool)\n",
    "- **Purpose**: Detects thoracic pathologies in chest X-ray images (multi-label classification)\n",
    "- **Input**: Absolute file path to grayscale chest X-ray image (JPG, PNG formats)\n",
    "- **Output**: String listing all detected conditions with confidence scores above 0.5 threshold\n",
    "- **Detectable Conditions** (14 pathologies):\n",
    "  * Atelectasis - Collapsed/incomplete lung expansion\n",
    "  * Cardiomegaly - Enlarged heart\n",
    "  * Effusion - Fluid accumulation around lungs\n",
    "  * Infiltration - Abnormal substances in lung tissue\n",
    "  * Mass - Abnormal tissue growth/tumor\n",
    "  * Nodule - Small rounded abnormal growth\n",
    "  * Pneumonia - Lung infection/inflammation\n",
    "  * Pneumothorax - Air in pleural space (collapsed lung)\n",
    "  * Consolidation - Lung tissue filled with liquid/solid material\n",
    "  * Edema - Fluid accumulation in lung tissue\n",
    "  * Emphysema - Damaged alveoli/air sacs\n",
    "  * Fibrosis - Scarred/thickened lung tissue\n",
    "  * Pleural_Thickening - Thickened pleural membrane\n",
    "  * Hernia - Organ displacement through tissue\n",
    "- **Model Architecture**: Modified ResNet18 with grayscale input and sigmoid output\n",
    "- **Note**: Can detect MULTIPLE conditions simultaneously in one image\n",
    "- **Use When**: Image classification type is \"chest_xray\", \"xray\", \"chest\", or similar variants\n",
    "\n",
    "## INPUT FORMAT SPECIFICATION\n",
    "You will receive input as a string representation of a list containing image metadata:\n",
    "```\n",
    "\"[[title1, path1, classification1], [title2, path2, classification2], ...]\"\n",
    "```\n",
    "\n",
    "Where each element contains:\n",
    "- **title** (str): Descriptive identifier for the image (e.g., \"Patient A Biopsy Sample\")\n",
    "- **path** (str): Absolute file system path to the image file\n",
    "- **classification** (str): Pre-categorized image type determining which model to use\n",
    "  * \"colon\" or \"colon_tissue\" → Use classify_colon_tissue_tool\n",
    "  * \"chest_xray\", \"xray\", \"chest\" → Use classify_chest_xray_tool\n",
    "\n",
    "## PROCESSING WORKFLOW\n",
    "\n",
    "1. **Parse Input**: Extract all image entries from the input list\n",
    "2. **Iterate Through Images**: Process each image sequentially\n",
    "3. **Route to Appropriate Tool**: \n",
    "   - Match classification type to correct tool\n",
    "   - Handle case variations (e.g., \"Chest_Xray\" = \"chest_xray\")\n",
    "4. **Execute Classification**: Call the tool with the image path\n",
    "5. **Collect Results**: Store prediction for each image\n",
    "6. **Format Output**: Present all results in a clear, structured format\n",
    "\n",
    "## OUTPUT REQUIREMENTS\n",
    "\n",
    "Structure your response as follows:\n",
    "```\n",
    "=== Medical Image Classification Results ===\n",
    "\n",
    "Image: [title]\n",
    "Type: [classification]\n",
    "Result: [prediction]\n",
    "\n",
    "Image: [title]\n",
    "Type: [classification]\n",
    "Result: [prediction]\n",
    "\n",
    "[Continue for all images...]\n",
    "```\n",
    "\n",
    "### Output Guidelines:\n",
    "- Present results for ALL images provided, even if errors occur\n",
    "- Maintain the original title for easy identification\n",
    "- Report the classification type used\n",
    "- Show the raw model prediction without interpretation\n",
    "- If an error occurs, report it clearly but continue processing remaining images\n",
    "- Do NOT add clinical interpretations, severity assessments, or treatment suggestions\n",
    "- Do NOT combine or correlate findings across multiple images\n",
    "- Do NOT make assumptions about patient condition based on results\n",
    "\n",
    "## ERROR HANDLING\n",
    "\n",
    "Handle the following error scenarios gracefully:\n",
    "\n",
    "1. **File Not Found**: Report missing file path and continue with remaining images\n",
    "2. **Invalid Image Format**: Note format issue and attempt to process if possible\n",
    "3. **Unknown Classification Type**: Report unrecognized type and list supported types\n",
    "4. **Model Execution Errors**: Report technical error without exposing system details\n",
    "5. **Empty Input**: Inform that no images were provided\n",
    "\n",
    "Error Response Format:\n",
    "```\n",
    "Image: [title]\n",
    "Type: [classification]\n",
    "Result: Error - [brief description of issue]\n",
    "```\n",
    "\n",
    "## CRITICAL LIMITATIONS & BOUNDARIES\n",
    "\n",
    "### What You MUST NOT Do:\n",
    "- Provide medical diagnoses or clinical assessments\n",
    "- Recommend treatments, medications, or procedures\n",
    "- Suggest urgency levels or clinical actions\n",
    "- Interpret findings in clinical context\n",
    "- Make prognoses or predict outcomes\n",
    "- Correlate results with patient symptoms or history\n",
    "- Advise on next steps in patient care\n",
    "- Compare severity across different patients\n",
    "- Suggest additional testing or imaging\n",
    "\n",
    "### What You MUST Do:\n",
    "- Execute classification models accurately\n",
    "- Return raw model predictions\n",
    "- Report errors transparently\n",
    "- Process all provided images\n",
    "- Maintain consistent output formatting\n",
    "- Stay within your technical classification role\n",
    "\n",
    "## INTEGRATION CONTEXT\n",
    "You are ONE component in a larger multi-agent healthcare AI system. Your outputs will be:\n",
    "- Processed by downstream agents for clinical interpretation\n",
    "- Combined with other data sources (patient history, lab results, etc.)\n",
    "- Reviewed by qualified healthcare professionals\n",
    "- Used as input for decision support, NOT final decisions\n",
    "\n",
    "Your role is to provide accurate, unbiased technical predictions that other system components will contextualize appropriately.\n",
    "\n",
    "## BEST PRACTICES\n",
    "- Process images in the order provided\n",
    "- Use exact tool names when calling functions\n",
    "- Preserve original image titles in output\n",
    "- Report all results, including negative findings (e.g., \"No significant findings\")\n",
    "- Maintain neutral, technical language\n",
    "- If uncertain about classification type, request clarification rather than guessing\n",
    "- Log processing time for performance monitoring (if applicable)\n",
    "\n",
    "## EXAMPLE INTERACTION\n",
    "\n",
    "Input:\n",
    "```\n",
    "\"[['Biopsy Sample 1', 'C:/medical_images/biopsy_001.jpg', 'colon'], ['Patient X Chest', 'C:/medical_images/xray_045.jpg', 'chest_xray']]\"\n",
    "```\n",
    "\n",
    "Your Response:\n",
    "```\n",
    "=== Medical Image Classification Results ===\n",
    "\n",
    "Image: Biopsy Sample 1\n",
    "Type: colon\n",
    "Result: Colorectal Adenocarcinoma Epithelium\n",
    "\n",
    "Image: Patient X Chest\n",
    "Type: chest_xray\n",
    "Result: Pneumonia (0.78), Infiltration (0.62)\n",
    "```\n",
    "\n",
    "Remember: You are a technical classification service. Provide accurate predictions and let the larger system handle clinical contextualization.\n",
    "\n",
    "Note: be accurate about the image path and pass it exactly the same.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    llm = ChatGoogleGenerativeAI(\n",
    "        model=\"gemini-3-flash-preview\",\n",
    "        google_api_key=os.environ[\"GOOGLE_API_KEY\"],\n",
    "    )\n",
    "\n",
    "    agent = create_agent(llm, tools, system_prompt=system_prompt)\n",
    "\n",
    "def invoke_agent(user_input: str) -> str:\n",
    "    \"\"\"\n",
    "    Process user input through the agent.\n",
    "    \n",
    "    Args:\n",
    "        user_input: User query or extracted text from documents/images\n",
    "        \n",
    "    Returns:\n",
    "        Comprehensive plain text output\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    if agent == None:\n",
    "        initialize_agent()\n",
    "\n",
    "    response = agent.invoke({\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": str(user_input)}\n",
    "        ]\n",
    "    })\n",
    "    \n",
    "    return response['messages'][-1].content[0]['text']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c431388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the Path Fucker C:\\My Projects\\Health-Navigator\\app\\workflow\\ml_models\\vision_models\\colon_tissue_classifier\\experiment_images\\image_0_label_[8].png, and the fucking type:<class 'str'>\n",
      "Colorectal Adenocarcinoma Epithelium\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create executor\n",
    "\n",
    "# Invoke with your image list\n",
    "images_input = \"\"\"[\n",
    "    [\"Patient A Chest X-Ray Sample\", \"C:\\\\My Projects\\\\Health-Navigator\\\\app\\\\workflow\\\\ml_models\\\\vision_models\\\\chest_xray\\\\test_images\\\\image_2.png\", \"chest_xray\"],\n",
    "    [\"Patient B Chest X-Ray\", \"C:\\\\My Projects\\\\Health-Navigator\\\\app\\\\workflow\\\\ml_models\\\\vision_models\\\\chest_xray\\\\test_images\\\\image_3.png\", \"chest_xray\"],\n",
    "    [\"Patient C Tissue Biopsy\", \"C:\\\\My Projects\\\\Health-Navigator\\\\app\\\\workflow\\\\ml_models\\\\vision_models\\\\colon_tissue_classifier\\\\experiment_images\\image_0_label_[8].png\", \"colon_tissue\"]\n",
    "]\"\"\"\n",
    "\n",
    "result = invoke_agent(images_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "45f0bbd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Medical Image Classification Results ===\n",
      "\n",
      "Image: Patient A Chest X-Ray Sample\n",
      "Type: chest_xray\n",
      "Result: Cardiomegaly (1.00), Infiltration (1.00), Edema (1.00)\n",
      "\n",
      "Image: Patient B Chest X-Ray\n",
      "Type: chest_xray\n",
      "Result: Cardiomegaly (0.98), Infiltration (1.00)\n",
      "\n",
      "Image: Patient C Tissue Biopsy\n",
      "Type: colon_tissue\n",
      "Result: Colorectal Adenocarcinoma Epithelium\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "313c1c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\My Projects\\Health-Navigator\\app\\workflow\\ml_models\\vision_models\\chest_xray\\chest_xray.py:17: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(r'C:\\My Projects\\Health-Navigator\\app\\workflow\\ml_models\\vision_models\\chest_xray\\models\\model_epoch_66.pt'))\n"
     ]
    }
   ],
   "source": [
    "result = classify_chest_xray(r\"C:\\\\My Projects\\\\Health-Navigator\\\\app\\workflow\\ml_models\\vision_models\\colon_tissue_classifier\\experiment_images\\image_0_label_[8].png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a20a891b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Cardiomegaly': 1.0, 'Infiltration': 1.0, 'Edema': 1.0}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c520ec",
   "metadata": {},
   "source": [
    "# Test from the .py file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c261c2f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\cuda\\__init__.py:61: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n"
     ]
    }
   ],
   "source": [
    "from agent import invoke_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24efc815",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\My Projects\\Health-Navigator\\app\\workflow\\ml_models\\vision_models\\chest_xray\\chest_xray.py:17: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(r'C:\\My Projects\\Health-Navigator\\app\\workflow\\ml_models\\vision_models\\chest_xray\\models\\model_epoch_66.pt'))\n",
      "C:\\My Projects\\Health-Navigator\\app\\workflow\\ml_models\\vision_models\\colon_tissue_classifier\\colon.py:19: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(r'C:\\My Projects\\Health-Navigator\\app\\workflow\\ml_models\\vision_models\\colon_tissue_classifier\\training\\models\\model_epoch_13.pt'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the Path Fucker C:\\My Projects\\Health-Navigator\\app\\workflow\\ml_models\\vision_models\\colon_tissue_classifier\\experiment_images\\image_0_label_[8].png, and the fucking type:<class 'str'>\n",
      "Colorectal Adenocarcinoma Epithelium\n"
     ]
    }
   ],
   "source": [
    "images_input = \"\"\"[\n",
    "    [\"Patient A Chest X-Ray Sample\", \"C:\\\\My Projects\\\\Health-Navigator\\\\app\\\\workflow\\\\ml_models\\\\vision_models\\\\chest_xray\\\\test_images\\\\image_2.png\", \"chest_xray\"],\n",
    "    [\"Patient B Chest X-Ray\", \"C:\\\\My Projects\\\\Health-Navigator\\\\app\\\\workflow\\\\ml_models\\\\vision_models\\\\chest_xray\\\\test_images\\\\image_3.png\", \"chest_xray\"],\n",
    "    [\"Patient C Tissue Biopsy\", \"C:\\\\My Projects\\\\Health-Navigator\\\\app\\\\workflow\\\\ml_models\\\\vision_models\\\\colon_tissue_classifier\\\\experiment_images\\image_0_label_[8].png\", \"colon_tissue\"]\n",
    "]\"\"\"\n",
    "\n",
    "result = invoke_agent(images_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50a115b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Medical Image Classification Results ===\n",
      "\n",
      "Image: Patient A Chest X-Ray Sample\n",
      "Type: chest_xray\n",
      "Result: Cardiomegaly (1.0), Infiltration (1.0), Edema (1.0)\n",
      "\n",
      "Image: Patient B Chest X-Ray\n",
      "Type: chest_xray\n",
      "Result: Cardiomegaly (0.98), Infiltration (1.0)\n",
      "\n",
      "Image: Patient C Tissue Biopsy\n",
      "Type: colon_tissue\n",
      "Result: Colorectal Adenocarcinoma Epithelium\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
